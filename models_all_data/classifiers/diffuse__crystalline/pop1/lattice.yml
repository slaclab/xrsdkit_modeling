cross_valid_results:
  accuracy: 0.9615384615384616
  all_labels: [F_cubic, hcp]
  confusion_matrix: "[[34  2]\n [ 0 16]]"
  f1: 0.9563025210084033
  minimization_score: -0.9615384615384616
  precision: 0.9444444444444444
  recall: 0.9722222222222222
default_val: null
features: [Imax_over_Imean, Ilowq_over_Imean, Imax_sharpness, I_fluctuation, logI_fluctuation,
  logI_max_over_std, q_Icentroid, q_logIcentroid, pearson_q, pearson_q2, pearson_expq,
  pearson_invexpq, q_best_hump, q_best_trough, best_hump_qwidth, q_best_hump_log,
  q_best_trough_log, best_hump_qwidth_log, best_trough_qwidth_log]
metric: accuracy
model:
  hyper_parameters: {C: 5.17947467923121}
  trained_par:
    classes_: [F_cubic, hcp]
    coef_:
    - [0.11303097859830442, 0.2931815720853109, -1.1537456515312883, 2.2557726975991326,
      -1.0449733262519978, -1.553982651625827, -0.5563283413820334, -0.37112883480294623,
      0.5951084877460406, 0.8060174836569702, 0.6382719005472163, -0.5516771418990417,
      -0.7142535709070674, -1.0852155493754527, 0.36830861155986533, -0.11973544173908172,
      -1.7040862715450502, 0.12651070049863067, 2.9922668031244504]
    intercept_: [-1.7714192034034084]
    n_iter_: 28
model_target: pop1_lattice
model_type: logistic_regressor
scaler:
  mean_: [20.655816290089795, 6.964303937941933, 2.0672327587680295, 0.3389422350106077,
    5.010070239684679, 2.8772182862769258, 0.06264985985607577, -0.1140580464509684,
    -0.5304363819031256, -0.39662605452973804, -0.49252307325697686, 0.5680817907544984,
    0.02179128221479832, 0.13593336255811475, 0.010819058119881798, 0.03685705111739043,
    0.13621537145842996, 0.13362950735155796, 0.002184166957514903]
  scale_: [11.121410570722789, 1.7123716970825844, 0.922121112058687, 0.2535746404418418,
    0.8349619347081572, 0.24430591227532827, 0.012361690607324935, 1.2644671024660181,
    0.06901042712797763, 0.04368002704860219, 0.06173596686702031, 0.07682607948654122,
    0.049060501048734974, 0.0053302575555123225, 0.015261428025104799, 0.22679423521379202,
    0.005102180871876644, 0.4288299481133261, 0.0004600894876418809]
trained: true
